import streamlit as st
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report
import plotly.express as px
import plotly.graph_objects as go

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(
    page_title="‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ",
    page_icon="üí∞",
    layout="wide"
)

# ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß
st.title("‚≠êÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ (Loan Default Prediction)")
st.markdown("‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ Machine Learning ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏Ç‡∏≠‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∞ \"‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ\"‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")

tab0, tab1, tab2, tab3, tab4 = st.tabs(["üìö ‡∏ó‡∏§‡∏©‡∏é‡∏µ", "üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "üîÑ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "ü§ñ ‡πÇ‡∏°‡πÄ‡∏î‡∏•", "üìà ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"])

with tab0:
    st.header("üìö ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    
    # ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á Random Forest
    st.subheader("üå≤ Random Forest")
    st.markdown("""
    **Random Forest** ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° (Ensemble Learning) ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Decision Trees) ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô
    ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö (Bootstrapping) ‡πÅ‡∏•‡∏∞‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏à‡∏∞‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (Feature) ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

    ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Å‡∏≤‡∏£ overfitting ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô

    **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Random Forest**
    - ‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£ overfitting
    - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
    - ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (Classification) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ñ‡πà‡∏≤ (Regression)
    - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ Feature Importance ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞
    
    **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡∏≠‡∏á Random Forest**
    - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏π‡∏á
    - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢

    **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô**:
    1. ‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Bootstrapping)
    2. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
    3. ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ (Majority Voting ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Classification)
    """)

    # ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Ç‡∏≠‡∏á XGBoost
    st.subheader("üöÄ XGBoost")
    st.markdown("""
    **XGBoost** (Extreme Gradient Boosting) ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ö‡∏ö Gradient Boosting ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏î‡πâ‡∏≤‡∏ô Machine Learning
    ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏• (Tree-based Models) ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö (Boosting) ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î

    **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á XGBoost**
    - ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô learning_rate, max_depth
    - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏î overfitting ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Regularization
    - ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (Classification) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ñ‡πà‡∏≤ (Regression)

    **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡∏≠‡∏á XGBoost**
    - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ
    - ‡∏´‡∏≤‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î overfitting ‡πÑ‡∏î‡πâ

    **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô**:
    1. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏• (Trees)
    2. ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Gradient (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô) ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö
    3. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÇ‡∏î‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î
    4. ‡∏Å‡∏≤‡∏£ Regularization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î overfitting
    """)

with tab1:
    st.header("‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå
    st.subheader("‚≠ê ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV")
    with st.expander("‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î"):
        st.code("""
from google.colab import files
import pandas as pd

uploaded = files.upload()
df = pd.read_csv('/content/Loan_default.csv')
        """)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏ò‡∏¥‡∏ï
    @st.cache_data
    def generate_sample_data():
        np.random.seed(42)
        
        data = {
            'loanid': list(range(1000, 1010)),
            'age': np.random.randint(20, 70, 10),
            'income': np.random.randint(20000, 150000, 10), 
            'loanamount': np.random.randint(5000, 100000, 10),
            'creditscore': np.random.randint(300, 850, 10),
            'monthsemployed': np.random.randint(0, 240, 10),
            'numcreditlines': np.random.randint(0, 15, 10),
            'interestrate': np.random.uniform(3, 20, 10).round(2),
            'loanterm': np.random.choice([12, 24, 36, 48, 60], 10),
            'dtiratio': np.random.uniform(0.1, 0.6, 10).round(2),
            'education': np.random.choice(['HighSchool', 'Bachelor', 'Master', 'PhD'], 10),
            'employmentstatus': np.random.choice(['Employed', 'Self-employed', 'Unemployed'], 10),
            'maritalstatus': np.random.choice(['Single', 'Married', 'Divorced'], 10),
            'homeownership': np.random.choice(['Own', 'Rent', 'Mortgage'], 10),
            'default': np.random.choice([0, 1], 10, p=[0.8, 0.2])
        }
        
        return pd.DataFrame(data)
    
    df = generate_sample_data()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    st.subheader("üîç ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    st.dataframe(df.head())
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        st.dataframe(df.describe().round(2))
    
    with col2:
        st.subheader("‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ")
        st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df)} ‡πÅ‡∏ñ‡∏ß")
        st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {len(df.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
        st.write(f"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ: {df['default'].mean()*100:.2f}%")

     # ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    st.subheader("üìö ‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    st.markdown("""
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å [Kaggle: Loan Default Dataset](https://www.kaggle.com/datasets/nikhil1e9/loan-default)

- **‡∏ä‡∏∑‡πà‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** Loan Default Dataset
- **‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥:** Nikhil Sharma
- **‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∞‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
""")

with tab2:
    st.header("üîÑ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
    st.subheader("‚ùì ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ")
    with st.expander("‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î"):
        st.code("""
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')
df[['loanamount', 'creditscore']] = imputer.fit_transform(df[['loanamount', 'creditscore']])
        """)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡πà‡∏≠‡∏ô-‡∏´‡∏•‡∏±‡∏á
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ")
        # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
        missing_df = df.copy()
        missing_df.loc[0:2, 'loanamount'] = np.nan
        missing_df.loc[3:4, 'creditscore'] = np.nan
        st.dataframe(missing_df[['loanamount', 'creditscore']])
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
        missing_counts = missing_df.isna().sum()
        st.write(f"‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå loanamount: {missing_counts['loanamount']}")
        st.write(f"‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå creditscore: {missing_counts['creditscore']}")
    
    with col2:
        st.subheader("‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ")
        imputer = SimpleImputer(strategy='mean')
        fixed_df = missing_df.copy()
        fixed_df[['loanamount', 'creditscore']] = imputer.fit_transform(missing_df[['loanamount', 'creditscore']])
        st.dataframe(fixed_df[['loanamount', 'creditscore']])
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
        fixed_missing_counts = fixed_df.isna().sum()
        st.write(f"‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå loanamount: {fixed_missing_counts['loanamount']}")
        st.write(f"‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå creditscore: {fixed_missing_counts['creditscore']}")
        
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    st.subheader("üè¢ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")
    with st.expander("‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î"):
        st.code("""
X = pd.get_dummies(df.drop(columns=['default', 'loanid'], errors='ignore'), drop_first=True)
y = df['default']
        """)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á One-hot encoding
    df_original = pd.DataFrame({
        'education': ['HighSchool', 'Bachelor', 'Master']
    })
    
    df_encoded = pd.get_dummies(df_original, drop_first=True)
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô One-hot encoding")
        st.dataframe(df_original)
    
    with col2:
        st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á One-hot encoding")
        st.dataframe(df_encoded)
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train/Test
    st.subheader("‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train/Test")
    with st.expander("‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î"):
        st.code("""
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        """)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á
    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=['‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'],
        x=[100],
        name='‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î',
        orientation='h',
        marker=dict(color='lightgrey')
    ))
    fig.add_trace(go.Bar(
        y=['‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'],
        x=[80],
        name='‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô (Train)',
        orientation='h',
        marker=dict(color='royalblue')
    ))
    fig.add_trace(go.Bar(
        y=['‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'],
        x=[20],
        name='‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö (Test)',
        orientation='h',
        marker=dict(color='lightcoral')
    ))
    fig.update_layout(
        title='‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö (80/20)',
        xaxis=dict(
            title='‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå',
            ticksuffix='%'
        ),
        barmode='stack',
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5)
    )
    st.plotly_chart(fig, use_container_width=True)

with tab3:
    st.header("ü§ñ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning")
    
    # Random Forest
    st.subheader("‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest üå≤")
    with st.expander("‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î"):
        st.code("""
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

rf_model = RandomForestClassifier(n_estimators=30, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
        """)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest
    st.subheader("‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Random Forest")
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ Plotly ‡πÅ‡∏ó‡∏ô
    fig = go.Figure()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
    for i in range(3):
        # ‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ
        fig.add_shape(type="rect", 
                     xref="x", yref="y",
                     x0=i*35, y0=0, x1=i*35+20, y1=10,
                     line=dict(color="brown"),
                     fillcolor="brown")
        
        # ‡∏Å‡∏¥‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ
        fig.add_shape(type="circle", 
                     xref="x", yref="y",
                     x0=i*35-10, y0=10, x1=i*35+30, y1=50,
                     line=dict(color="green"),
                     fillcolor="green")
        
    fig.update_layout(
        height=200,
        width=600,
        title="Random Forest - Multiple Decision Trees",
        showlegend=False,
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # XGBoost
    st.subheader("‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost üöÄ")
    with st.expander("‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡πâ‡∏î"):
        st.code("""
import xgboost as xgb

xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)
xgb_model.fit(X_train, y_train)
        """)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå Random Forest")
        st.markdown("""
        - n_estimators: 30
        - criterion: gini
        - max_depth: None
        - min_samples_split: 2
        - min_samples_leaf: 1
        - random_state: 42
        """)
    
    with col2:
        st.subheader("‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå XGBoost")
        st.markdown("""
        - n_estimators: 100
        - learning_rate: 0.1
        - max_depth: 6
        - booster: gbtree
        - subsample: 1
        - random_state: 42
        """)

with tab4:
    st.header("üìà ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏°‡∏°‡∏ï‡∏¥
    rf_accuracy = 0.82
    xgb_accuracy = 0.87
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    st.subheader("üéØ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    models = ['Random Forest', 'XGBoost']
    accuracy = [rf_accuracy, xgb_accuracy]
    
    fig = px.bar(
        x=models, 
        y=accuracy,
        text=[f"{acc:.2%}" for acc in accuracy],
        color=accuracy,
        color_continuous_scale='Blues',
        title="‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"
    )
    fig.update_layout(
        xaxis_title="‡πÇ‡∏°‡πÄ‡∏î‡∏•",
        yaxis_title="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (Accuracy)",
        yaxis=dict(tickformat=".0%", range=[0, 1])
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    st.subheader("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    predictions = {
        '‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ID': [1001, 1002, 1003, 1004, 1005],
        '‡∏≠‡∏≤‡∏¢‡∏∏': [35, 42, 28, 55, 33],
        '‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ': [50000, 80000, 35000, 120000, 65000],
        '‡∏¢‡∏≠‡∏î‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠': [25000, 65000, 15000, 85000, 35000],
        '‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Random Forest)': ['‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î'],
        '‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (XGBoost)': ['‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î'],
        '‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á': ['‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î', '‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î']
    }
    predictions_df = pd.DataFrame(predictions)
    st.dataframe(predictions_df)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    st.subheader("‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢
    feature_importance = {
        '‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢': ['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ', '‡∏≠‡∏≤‡∏¢‡∏∏', '‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô'],
        '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç': [0.35, 0.25, 0.15, 0.12, 0.08]
    }
    feature_df = pd.DataFrame(feature_importance)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢
    fig = px.bar(
        feature_df,
        x='‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç',
        y='‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢',
        orientation='h',
        color='‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç',
        color_continuous_scale='Blues',
        title="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"
    )
    fig.update_layout(
        xaxis_title="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç",
        yaxis_title="‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢",
        xaxis=dict(tickformat=".0%"),
        yaxis=dict(categoryorder='total ascending')
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    st.markdown(f"""
    - Random Forest ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {rf_accuracy:.2%}
    - XGBoost ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô {xgb_accuracy:.2%}
    """)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠
    st.subheader("‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠")
    st.markdown("""
    1. ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
    2. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô Neural Network
    3. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
    4. ‡∏ó‡∏≥ Feature Engineering ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞
    """)